# Домашнее задание 5
При запусках я использовал репликацию на кворум, то есть каждый ключ хранится на 2 нодах, нагрузку давал 2 минуты.

## Профиль, put запросы
### wrk
![](resources/wrk_put_11k_rps.png)  
Приложение стабильно работает на 11k rps.

![](resources/wrk_put_12k_rps.png)  
В целом приложение справляется и с 12k rps, но latency на 90-м персентиле становится слишком большой.  
По сравнению с предыдущими двумя этапами приложение сильно ускорилось за счет отсутствия активного ожидания от запроса на другую ноду.     

### cpu
![](resources/cpu_put_profile.png)
* Время на взятие таски воркерами уменьшилось с 22% до 5%. Я думаю, это связано с повышением rps. Приложение стало быстрее обрабатывать запросы, я поднял rps, запросов стало больше, значит они чаще приходят к воркерам, значит каждому воркеру приходится меньше ждать следующую таску.      
* Время на `select` в `HttpClientImpl` уменьшилось с 18% до 16%. Думаю, здесь нет проблемы. С одной стороны запросов стало сильно больше, значит и `select` будет вызываться чаще. С другой стороны, если запросов больше, то в методе `select` будет меньше ожидания новых запросов, ведь они приходят чаще. В общем, тут не ясно, но проблем не вижу, `SelectorManager` делает свою работу.  
* В `SelectorThread` сервера увеличилось на 1% время добавления таски в пул воркеров, причем выросло оно из-за метода `ReentrantLock#unlock`, который внутри себя делает `unpark` следующему в очереди на лок. Это эффект от того, что rps x повысился и воркеры стали намного активнее взаимодействовать с очередью задач, тем самым вызывал лишние расходы на добавление задачи.  
* В воркер треде с 2,75% до 0,06% уменьшилось активное ожидание за счет того, заменил `CompletableFuture#get` на честно асинхронную работу. А также заменил логику с `CountDownLatch` на `synchronized` методы и работу с примитивами. Основная причина смены на `synchronized` - простота реализации. Я решил не делать преждевременные оптимизации, а сделал простое рабочее решение. Так как я не увидел в профиле cpu и lock проблемы, связанной с `synchronized`, то считаю решение правильным. В этом дз логика с `CountDownLatch` у меня стала слишком сложной и не очевидно правильной, поэтому переделал. Да и в целом replication фактор редко бывает большим (обычно 2-3), поэтому сильной конкуренции на этом `synchronized` и нет, особенно, учитывая, что обычно свой рандом вносит сеть до разных реплик, и их ответы приходят не одновременно.
* Время в методе `select` у `SelectorThread` увеличилось с 2,5% до 3,8%. И я не вижу в этом ничего плохого, ведь это означает, что таски быстрее долетают до воркеров, а селектор тред садится в ожидание новых. Я специально сделал `submitTask` в пул воркеров пораньше в коде, чтобы селектор тред занимался только селектом запросов, валидацией параметров и определением реплик. Да, я считаю, что валидация параметров дешевле чем submit отдельной задачи в пул воркеров, потестировал это, правда приложение немного замедлилось.

### alloc
![](resources/alloc_put_profile.png)
* 0,5% аллокаций добавились из-за `thenAccept` и `exceptionally` у `CompletableFuture`  
* В селектор треде изменений не вижу
* 30% аллокаций на `sendResponse`, то есть на отправку ответа клиенту. Хорошо, что их так много, потому что все эти аллокации не лишние. А вот в профиле 4 дз аллокации на отправку ответа не так явно видны, а сильно размазаны по профилю. Так что это я считаю улучшением.
* Убрал из селектор треда аллокации на создание `URI`, о которых писал в прошлом дз.

### lock
![](resources/lock_put_profile.png)
* На взятие задачи из пула потоков тратится всего 0,2% локов, даже не сразу нашел это в профиле.
* Работа с бд занимает примерно 0,6% локов.
* Блокировки связанные с `synchronized` в логике состояния лидера я не нашел в профиле, видимо, они занимают относительно малую часть.
* Остальное - блокировки, связанные с `HttpClient` и `CompletableFuture`. Там очень много локов в `SelectorManager`, но их можно объяснить, ведь `SelectorManager` инкапсулирует внутри себя очень много разных действий: там и селектор тред внутри, и пул соединений, и набор входящих событий, в общем, сложное состояние, которое хочется менять атомарно, поэтому там и берется здоровенный `synchronized(this)`.   

В общем, performance значительно улучшился, активного ожидания стало сильно меньше, в профиле локов нет ничего лишнего. Из доработок я бы посмотрел внимательнее на профиль аллокаций, там очень много мелких аллокаций, если внимательно на них посмотреть, есть большой шанс найти не необходимые аллокации. Мб займусь этим на 2 неделе дз. 

## Профиль, get запросы

### wrk
![](resources/wrk_get_13k_rps.png)  
Приложение хорошо справляется с 13k get запросов.  

![](resources/wrk_get_14k_rps.png)  
С 14k запросов приложение скорее не справляется, даже 50-й персентиль великоват.  

Интересно, что performance get запросов стал лучше, чем у put запросов как минимум на 1k rps.  
Возможно, это связано с тем, что в put запросах на реплики передается timestamp, а в get запросах нет.  

### cpu
![](resources/cpu_get_profile.png)  
Если сравнивать с дз-4, то:
* Ушли 4,5% cpu на `CompletableFuture#get`.  
* Уменьшилось ожидание воркером на взятие таски из пула с 18% до 4,5%.  
* Появилось ожидание 5,5% на ожидание таски воркером из `ForkJoinPool`, в который летят задачи `sendAsync` при запросе к реплике.
* В целом за счет `thenApply` 11% cpu по аггрегации ответов с реплик и отправке ответа клиенту перетекли в `ForkJoinPool`.  
* Время в `select` селектор треда `HttpClient` уменьшилось с 20% до 13%. Это явно объясняется повышением rps. Запросы происходят чаще, значит ждать их в `select` приходится меньше времени.  
* Время работы в `SelectorThread` сервера повысилось с 4% до 12%. Думаю, это связано с повышением rps.
 
### alloc
![](resources/alloc_get_profile.png)  
В целом профили у get и put похожие, но есть отличия:
* ![](resources/alloc_diff.png)  
В get запросах при обработке запроса лидером (когда нужное число реплик уже ответили) происходит много аллокаций. Часть из них из-за моих любимых стримов. Если все просуммировать, то 3,5% аллокаций - доп расход на стримы. Пока оставлю так, потому что код получаетсяс очень красивый, читаемый, простой и понятный. На след неделе может займусь тюнингом аллокаций.    
* В том же месте происходит десериализация ответов с реплик. На мой взгляд, сериализатор не аллоцирует лишнего: `ByteBuffer#wrap` для распаршенного значения и новый объект `DBValue`. Пока не вижу, как тут уменьшить аллокации.  
* В `SelectorThread` при чтении данных, парсинге запроса и определении шарда в get запросах стало больше аллокаций. Причем в put запросах 8% аллокаций уходило на body, а в get запросах этих аллокаций нет. Зато там аллокации от консистетного хеширования занимают 9% аллокаций, а не 4,5%, как в put запросах. Могу предположить, что аллокаций на get запросах суммарно меньше, поэтому в процентном соотношении в `SelectorThread` виден рост. В это можно поверить, сравнив аллокации на методе `select` при равном rps, который абсолютно одинаково работает в случае get и put. Там в put запросах 1,91% аллокаций, а в get запросах 1,07%. Поэтому подтверждаю предположение.   

### lock
![](resources/lock_get_profile.png)  
* По сравнению с put запросами на 3% выросли локи в `SelectorManager`. Это явно связано с тем, что в get запросах больший rps, потому что больше rps, значит `SelectorManager` должен оркестрировать большее число запросов, логично что при этом contention на ресурсах самого `SelectorManager` становится больше, что и влечет большее число локов.

## Вывод
* Значительно улучшился performance приложения.
* Значительно уменьшилось активное ожидание за счет асинхронного подхода.
* Значительно улучшился профиль блокировок, остались только локи от `HttpClient$SelectorManager`.

### Доделки на 2-й неделе
* Переписал `synchronized` методы в lock-free стиле через cas. Отличий в performance и профилях не заметил, что логично, потому что операции под `synchronized` были очень легковесные и конкуренция за лок между потоками небольшая.
* Заметил в readme, что по умолчанию надо реплицировать на весь кластер, сделал дефолтное значение `ack` равным размеру кластера. Разумеется, при этом предельный rps значительно упал, потому что теперь стало сильно больше тасок в тредпулах, в частности, теперь каждый запрос генерирует 2 похода по сети на реплику, то есть также забивается пул `HttpClient`, также намного большая нагрузка падает на `SelectorThread` внутри `HttpClient`. Более подробный анализ будет в ветке с бонусным заданием.
* Сделал `thenAcceptAsync` и передал в качестве пула потоков executor от воркеров, чтобы обработка ответов от реплик происходила точно не в пуле потоков внутри `HttpClient`. Так получается более логичное разделение работы по пулам. Причем я не вижу смысла на данный момент заводить отдельный пул для обработки результатов от реплик, потому что воркеры хорошо справляются со своими задачами и их будет здорово загрузить еще порцией легких тасок (что они хорошо справляются видно по времени ожидания на взятие таски из пула, если бы воркеры не справлялись, то в очереди всегда было бы некоторое количество задач и взятие таски не влекло бы ожидание).
* ![](resources/visualvm.png)  
Посмотрел через VisualVM, какие потоки как заняты при предельном rps. Можно сделать выводы:
1) Все селекторы заняты своим делом.
2) Воркеры легко справляются со своими задачами, учитывая, что я создавал пул с максимум 8-ю потоками, а по факту воркер тредов создалось лишь 2, остальные не создавались за ненадобносстью.
3) Воркеры в пуле `HttpClient`, тоже справляются с задачами, хотя им тяжелее. В текущей конфигурации у меня в этом пуле 2 потока, но были запуски и с 8-ю, поэтому они остались в visualVM. Видно, что из 2-х потоков используется только один. Это, кстати, еще одно свидетельство, что у меня в коде нет активного ожидаения на `CompletableFuture`, ведь если бы оно было, то первый поток из пула остановился на период времени, и тогда внутри пула был бы создан второй поток для обработки задач в данный момент. Такого не произошло, значит активного ожидания не было, по крайней мере не было дольше чем время между поступлениями задачи в пул `HttpClient`.
4) Все-таки иногда `CompletionStage` выполняются в common pool, хотя я постарался этого избежать. На скрине с visualVM как раз видно, почему это плохо: у меня сейчас аж 6 активных потоков в коммон пуле, из которых только в каком-то одном иногда выполняется какая-то задача.

![](resources/visualvm2.png)  
Разобрался в сабмитами задач в common pool. Во-первых, я сделал `corePoolSize` равным 2, за счет этого в пуле у меня было 2 воркера и реже происходила ситуация, что все потоки заняты какой-то работой и таска вынуждена ожидать, из-за этого действия в common pool стало попадать сильно меньше задач, буквально одна за весь период нагрузки (1 мин). Во-вторых, на скрине ясно видно, что задача попала в common pool именно тогда, когда оба воркера `httpClientThread` были заняты работой. Поэтому, чтобы избегать попадания задач в common pool нужно не допускать, чтобы все потоки `httpClientThread` заняты делом.  
За счет всех перечисленных действий удалось улучшить performance приложения и поднять предельный rps до 12500.
![](resources/wrk_put_12500_rps.png)