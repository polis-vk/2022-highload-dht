# Тестирование новой версии
Чтобы обрабатывать больше одновременных соединений, реализуем обработку запросов в отдельном тредпуле, чтобы селекторы могли
лучше выполнять свою работу. Для этого используем ThreadPoolExecutor с LIFO-очередью (java.util.concurrent.LinkedBlockedQueue).

Размер тредпула установим в ncpus/2+1 (чтобы учесть гипертрединг)
На моей машине с Intel Core i7-10510U и восемью логическими ядрами сервер создаёт 5 worker-потоков.
## Заполнение при помощи `PUT` в одно соединение
```text
./wrk -c 1 -t 1 -R 30000 -d 30 -s ~/study-files/highload/lua/put.lua http://localhost:19234

Running 30s test @ http://localhost:19234
  1 threads and 1 connections
  Thread calibration: mean lat.: 89.634ms, rate sampling interval: 463ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    14.01ms   26.78ms 131.33ms   89.66%
    Req/Sec    30.12k     1.32k   33.89k    86.05%
  899954 requests in 30.00s, 57.50MB read
Requests/sec:  29998.73
Transfer/sec:      1.92MB
```
Гораздо хуже, чем первая версия (>x10). Посмотрим, как будут обрабатываться 64 соединения
## Заполнение при помощи `PUT` в 64 соединения
```text
./wrk -c 64 -t 6 -R 30000 -d 30 -s ~/study-files/highload/lua/put.lua http://localhost:19234

Running 30s test @ http://localhost:19234
  6 threads and 64 connections
  Thread calibration: mean lat.: 0.844ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 0.833ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 0.842ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 0.869ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 0.906ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 0.853ms, rate sampling interval: 10ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     0.87ms  464.38us  12.38ms   68.91%
    Req/Sec     5.24k   270.77    10.00k    82.22%
  899246 requests in 30.00s, 57.46MB read
Requests/sec:  29977.98
Transfer/sec:      1.92MB
```
Укладываемся в 1ms. Это значит, что наш сервер стал хуже обрабатывать соединения по отдельности, но прекрасно
справляется при распределении нагрузки. Давате попробуем повысить RPS.
```text
./wrk -c 64 -t 6 -R 50000 -d 30 -s ~/study-files/highload/lua/put.lua http://localhost:19234

*в логе куча ошибок и OutOfMemoryError*
```
Сервак умер :(
### Чтение заполненной базы при помощи `GET`
```text
./wrk -c 1 -t 1 -R 30000 -d 30 -s ~/study-files/highload/lua/get.lua http://localhost:19234

Running 30s test @ http://localhost:19234
  1 threads and 1 connections
  Thread calibration: mean lat.: 361.982ms, rate sampling interval: 1054ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     1.61s   696.33ms   3.42s    68.49%
    Req/Sec    26.10k     2.19k   28.26k    77.78%
  797425 requests in 30.00s, 150.39MB read
  Non-2xx or 3xx responses: 647533
Requests/sec:  26580.95
Transfer/sec:      5.01MB
```
Ничего не поменялось с первой стадии... Попробуем распараллелить.
### Чтение при помощи `GET` в 64 соединения
```text
./wrk -c 64 -t 6 -R 30000 -d 30 -s ~/study-files/highload/lua/get.lua http://localhost:19234
Running 30s test @ http://localhost:19234
  6 threads and 64 connections
  Thread calibration: mean lat.: 0.847ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 0.845ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 0.797ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 0.852ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 0.845ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 0.873ms, rate sampling interval: 10ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   818.68us  415.15us   9.50ms   62.50%
    Req/Sec     5.25k   244.12     9.10k    60.72%
  899308 requests in 30.00s, 646.67MB read
Requests/sec:  29977.75
Transfer/sec:     21.56MB
```
Это в три раза лучше первой стадии! Теория из первого отчёта оказалась верна.

# Flamegraph

Проанализировав flamegraph, можно сделать следующие выводы:

* При росте числа соединений растёт контеншн на локах (ожидаемо) 
* 15% времени CPU занимают блокировки (обработка LIFO очереди)
* Мы стали меньше проводить времени в сисколлах, и активнее читать с диска