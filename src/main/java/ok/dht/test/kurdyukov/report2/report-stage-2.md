# Отчет

## Введение

При выполнении второго этапа. Я решил и на дальнейших этапах использовать `LevelDB`. База thread - safe на put, get,
delete.

Из замечаний прошлого этапа было исправлено:

    httpServer.addRequestHandlers(this);
    httpServer.start();

Стартовать нужно после того как заматчил хенедлеры.

## Ход работы.

Модель асинхронного сервера стала следующей:

1. Изменилось количество селекторов 1 -> кол-во процессов / 2. В моем случае 6. Этот совет был дан нам на лекции (чтобы
   не париться). В целом неплохой подход разделить количество доступных процессов на обработку и слушание каналов.

2. По итогу размер тредпула обработчиков (логика взаимодействия с бд) поставил 32. Дальше будут приведены цифры. Размер
   очереди задач THREAD_POOL_SIZE * 4, дабы не отказывать при большой нагрузке моментально, а дать шанс пождать в
   очереди.

Таким образом селектор делегирует сложную задачу поход в бд на воркеров. Тем самым можем ответить на следующий запрос.

Так же нагружаем бд 5 минут с 50к rps. Двумя способами с размером тредупулом размера 32, и кол-во процессов / 2 + 1.

```
kurdyukov-kir@i109817004 lua % wrk2 -d 5m -c 64 -t 64 -s put_http_query.lua -R 50000 http://localhost:4242

  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    18.86s    23.86s    1.97m    83.36%
    Req/Sec   609.35    356.03     4.75k    62.80%
  11006690 requests in 5.00m, 709.01MB read
  Non-2xx or 3xx responses: 500287
Requests/sec:  36685.16
Transfer/sec:      2.36MB
```

База захлебнулась на 7 потоках. И мы получаем очень много отказов.

```
kurdyukov-kir@i109817004 lua % wrk2 -d 5m -c 64 -t 64 -s put_http_query.lua -R 50000 http://localhost:4242

  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     6.09ms    6.70ms  35.58ms   78.28%
    Req/Sec   790.40    187.59     1.26k    61.10%
  1499253 requests in 29.99s, 95.80MB read
Requests/sec:  49997.34
Transfer/sec:      3.19MB
```

При 32 потоков мы держим нагрузку. Это возможно связано с тем, что процесс умеет эффективно управлять довольно небольшим
числом потоков. Также возможно сказалось, то что ноут был без зарядки. К слову, выдерживаемая нагрузка выросла в 8 раз
по сравнению с предыдущим этапом. В целом пока неважно, небольшое количество поток довольно хорошо управляется джавой.

Посмотрим на cpu, alloc, lock:

[cpu](./profiler/png/put_cpu.png) - видим, что 60% cpu как раз уходит на работу воркеров. Половина из этих процентов
тратиться на блокировку в ожидании следующих задач, а другая на ответ пользователю и поход в базу. Т.е очередь успевает
разгребаться. Остальные 40 % уходят на работу селекторов, one-nio. То есть получилось в равной степени распределить
ресурсы. Вполне справедливо, что воркеры едят больше ибо на них поход в базу и ответ пользователю.

[alloc](./profiler/png/put_alloc.png) - в целом поведение не изменилось от предыдущего этапа. Большая часть алокаций
уходит на потребности базы данных. На формирование "таблеток" (батчей на выгрузку в память). Остальные алокации делаются
one-nio на ответы запросов.

[lock](./profiler/png/put_lock.png) - вполне ожидаемо, что блокировки пришлись на тредпул обработчиков. Блокировками мы
ждем следующие задачи, а также происходит синхронизация базы.

Захлеб сервера происходит при 70к rps.

```
 wrk2 -d 30 -c 64 -t 64 -s get_http_query.lua -R 70000 -L http://localhost:4242
 
   Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     3.33s   928.80ms   4.96s    59.57%
    Req/Sec     0.91k    22.92     0.95k    51.94%
  Latency Distribution (HdrHistogram - Recorded Latency)
 50.000%    3.41s 
 75.000%    4.11s 
 90.000%    4.56s 
 99.000%    4.85s 
 99.900%    4.93s 
 99.990%    4.96s 
 99.999%    4.96s 
100.000%    4.96s 
```

Ответы в среднем стали составлять 3 секунды. Что ж результат в 50к рпс меня вполне устраивает :)

На GET запросы картина аналогичная 7 потоков не выдерживает нагрузку в 50к rps, а 32 удерживает.

```
kurdyukov-kir@i109817004 lua % wrk2 -d 5m -c 64 -t 64 -s get_http_query.lua -R 50000 http://localhost:4242

  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    18.86s    23.86s    1.97m    83.36%
    Req/Sec   609.35    356.03     4.75k    62.80%
  11006690 requests in 5.00m, 709.01MB read
  Non-2xx or 3xx responses: 500287
Requests/sec:  36685.16
Transfer/sec:      2.36MB
```

18 секунд в среднем на ответ - неприемлемый результат, что не сказать о 32 потоках.

```
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     4.05ms   22.14ms 282.62ms   97.60%
    Req/Sec   829.81    169.46     6.67k    96.65%
  1499531 requests in 29.99s, 1.07GB read
  Non-2xx or 3xx responses: 3531
Requests/sec:  50001.15
Transfer/sec:     36.54MB
```

4 мc - результат вполне хороший, даже чуть лучше, чем в put, скорее всего это вызвано тем, что я подключил зарядку к
ноуту. И немножко прогрелся.

Небольшой анализ cpu, alloc, lock:

[cpu](./profiler/png/get_cpu.png) - ситуация аналогична как в put. Большая часть cpu уходит на сеть. Нежели на поход в
базу. Так как в воркерах мы снова идем в сеть.

[alloc](./profiler/png/get_alloc.png) - здесь в отличие от put, 85 процентов аллокаций уходят на работу с базой данных,
причина та же, что и на прошлом этапе. Мы беспорядочно ходим в диск выгружая батчи. Опять же особенность LSM, которая
ориентирована на запись.

[lock](./profiler/png/get_lock.png) - в отличие от put появились локи вне тредпула воркеров.

## Выводы

За счет асинхронной обработки наш летенси сервиса вырос в 7 - 8 раз в зависимости от типа запроса. В целом замечания об
тонкостях бд остаются верны и с предыдущего этапа. На этом этапе можно пытаться оптимизировать с тем, чтобы взять
потокобезопасный стэк или лок-фри очередь для обработки запросов MS-queue, к примеру. Но, например, в очереди Майкла -
Скотта нельзя задать капасити, в связи с тонкостями реализации :) (очень тяжело синхронизироваться по размеру и
смотреть, чтобы мы не вышли за его приделы). Также можно оптимизировать свой кастомный http - server. Например, если
поправить прикол с тем, что если зафиксировать ответ к примеру Response на BAD_REQUEST. То там будут дописывать хедер на
каждый запрос клиента. В конечном счете он станет просто очень большим, и мы не сможем передавать его по сети.

Но все это несильно даст нам буста, так чтобы в разы. Следующая закономерная оптимизация - вертикальное масштабирование!