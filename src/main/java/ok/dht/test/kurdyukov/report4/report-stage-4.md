# Отчет

## Введение

С прошлого этапа были удалены листенеры, которые обеспечивали circuit breaker.
По двум причинам:

1. Этот подход не будет работать на большом кластере. Ибо мы неспособны создать тысячи тредов, которые будут слушать
   каждый узел.
2. Также для того, чтобы код стал более читаемый.
3. Экономия ресурсов локальной машинки. Ибо потоки нужны и для wrk2, а также для кластера из 3 нод.

Также был сильно изменена структура проекта:

1. Был сделан класс для работы с базой была вынесена в `DaoRepository`. Здесь мы никак не взаимодействуем с `one-nio`.
2. `DaoEntry` класс обертка над данными, которые в итоге хранятся в сериализованном виде. Это timestamp, value,
   isTombstone.
3. Классы, которые взаимодействуют с http теперь лежат в пакете `http`.
4. Также появился `ObjectMapper`, который сериализует и десериализует DaoEntry.

Также с преподавательским составом утвердилось то, что мы доверяем пользователю. Например, он не может что - то положить
в хедер. Также общение внутри кластера также доверительное.

Считаем как будто перед нами стоит nginx.

## Описание работы кластера

Обработка пользовательских запросов имеет два четких этапа (и неважно, какая нода стала обрабатывать запрос
пользователя):

1. Multicast размера `from`. Возможно сообщение будет отправлено само себе. Опять же для удобства, сообщения
   рассылаются асинхронно.
2. Блокируемся и дожидаемся ответов, делаем мерж результатов.

При удалении происходит пут пустого массива байт с флажком "могилки".

Политика реплицирования была выбрана следующая. Все ноды стартуют с одним и тем же порядоком урлов кластера.
С помощью консистетного хеширования мы находим ноду куда нужно реплицироваться. Затем берем следующие from - 1 узлов и
на них реплицируем.

## Ход работы

При нагрузочном тестировании использовался кластер из трех нод. Параметры для реплицирования были следующими ack = 2 и
from = 3.

Результаты обстрела на PUT на 4000 rps. Свыше 7000 rps кластер захлебывается.

````
wrk2 -d 1m -c 5 -t 5 -s put_http_query.lua -R 2000 http://localhost:4242
Running 1m test @ http://localhost:4242
  5 threads and 5 connections
  Thread calibration: mean lat.: 1.917ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.886ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.954ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.949ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.954ms, rate sampling interval: 10ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     2.27ms    4.71ms  51.10ms   95.15%
    Req/Sec   422.42    107.41     1.22k    84.24%
  120004 requests in 1.00m, 7.67MB read
Requests/sec:   2000.00
Transfer/sec:    130.86KB
````

Итак, главная проблема - это получение результата.
Здесь я использую на данный момент наивный подход. Прохожусь по листу `Futures` моих запросов к нодам pазмера `form`.

Важное замечание: асинхронный мультикаст хорошо, даже очень. Но вот дожидаться form запросов - это место, которое
требует улучшения.

А именно давай те заведем AtomicInteger, и будем передавать его в handleAsync. Те фьючи, которые отработали, будут
инкрементить этот инт. И как только он станет == ack, мы сделаем notify главного потока. Который мы усыпим `wait`.
Тем самым мы не будем ждать form - ack запросов.

Посмотрим на результаты профилирования PUT.

alloc - [alloc](./profiler/png/put_alloc.png). Сразу можно заметить, что `Stream Api` начала откусывать заметную часть
наших алокаций и cpu [cpu](./profiler/png/put_cpu.png). Читаемость кода требует жертв. Но здесь это вполне оправдано.
Все - таки мы утыкаемся в репликацию нежели мерж через стримы. [lock](./profiler/png/put_lock.png) Локи не изменились по
сравнению с предыдущим этапом. Большую часть локов съедает тредпул и где - то 25 процентов селекторы. Вполне справедливо
ибо на тредпул приходиться походы в базу, сериализация и десериализация, multiselect. Задач больше копиться в очереди.

Также возможное улучшение - это не наивный `serialize`. Умудриться сделать без оберток и тому подобных вещей. Дописывая
байты.

Результаты обстрела GET на 4000 rps. Аналогично, что и PUT захлебывается свыше 6000 rps

```
wrk2 -d 1m -c 5 -t 5 -s get_http_query.lua -R 4000 http://localhost:4242
Running 1m test @ http://localhost:4242
  5 threads and 5 connections
  Thread calibration: mean lat.: 1.470ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.459ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.719ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.481ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.465ms, rate sampling interval: 10ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     1.20ms  464.42us  19.02ms   79.21%
    Req/Sec   422.75     60.57     1.00k    70.31%
  120002 requests in 1.00m, 87.88MB read
```

Профилирование GET показало по модулю те же результаты. Локи в таком же соотношении берутся.

Важное замечание!

Давайте еще раз посмотрим на траты cpu у GET и
PUT [get_cpu](./profiler/png/get_cpu.png) [put_cpu](./profiler/png/put_cpu.png) соответственно.

Мы видим, что огромная часть ресурсов cpu уходит на парковку треда. С чем это связано?
Мой ответ следующий: первая причина, что мои клиенты используют CachedTreadPool - это тредпул нефиксированного размера.
То есть на каждую новую задачу он выделяет поток или переиспользует ранее выделенный. Поток выделяется в моем случае на
60s. И когда их становится много, их нельзя убить сразу, не подождав минуты. А задачи идут массивом, и поток приходиться
будить, и затем снова парковать. Вторая причина: не стоит забывать, что у меня 3 ноды, которые борются за ядра
компьютера. А также wrk. Это также пораждает парковки тредов.

CachedThreadPool - мной использовался, потому что не хватало какого - то фиксированного тредпула, чтобы справляться с
нагрузкой. Тогда еще 15к рпс хотелось держать. И это слабое место, которое требует улучшений, как скорости и
оптимального использования ресурсов. А также отказоустойчивости нашего кластера. Ибо порождать можно треды очень много.
А это дорого по памяти, из-за чего может переполниться куча.

Про аллокации. Проблема лишней аллокаций стримов отобразилась как и на PUT, так и на GET. Возможно, с одной стороны
пренебречь читаемостью и сэкономить ресурсы. С другой, это не значительно по сравнению с походами по сети.
В целом заметно [get_alloc](./profiler/png/get_alloc.png) [put_alloc](./profiler/png/put_alloc.png) как сильно съедает
ресурсов http client java.net. Возможно его можно заметить на клиента one-nio. (Но кажется он не умеет в асинхронность)

## Выводы

Итого выше было перечисленно ряд улучшений, которые можно проделать.
Можно еще раз указать за и против.

Первое важное замечание про синхронное ожидания листа респонсов размера `form`.
С одной стороны дождавшись всех ответов мы дадим более корректный ответ пользователю, ибо мы будем мержить все живые
ноды, ибо запоздалая нода будет иметь более свежий timestamp. А с другой стороны мы вроде как не давали строгих
гарантий, здесь не Raft и не Paxos. Мы работаем на скорость.
Поэтому возможно вполне разумно игнорировать оставшиеся `form` - `ack` запросов. И торопиться отвечать пользователю. Но
тут зависит от наших гарантий.

Второе важное замечание `Stream Api`. Оправдано ли использование? С одной стороны да код стал очень читаемым и понятным,
и по сравнению с походом в сеть - это малая жертва. С другой стороны, нужно беречь ресурсы и стараться делать как можно
меньше действий.

Третье важное замечание Serializer. Сейчас я использую классический подход, который предлагает джава из коробки. Так же
есть Serializer от one-nio. Здесь проблема, что эти сериалазеры аллоцируют большое количество лишних бит, для своей мета
инфы. Можно придумать подход, чтобы самим дописывать в тело байты, отвечающие за tombstone и timestamp. Это явно ускорит
наш кластер. Ибо в профилировании также заметны лишние аллокации и траты cpu моего сериалайзера.

В рамках экономии ресурсов был выпилен circuit - breaker. Его стоит вернуть для того, чтобы кластер был более
отказоустойчив. Ведь теперь у нас гораздо большая вероятность попасть в заболевшую ноду (мы делаем мультикаст).

И последний тезис нужно ускорять работу с сетью попробовать использовать другого клиента. Но вот one-nio к сожалению
синхронный.