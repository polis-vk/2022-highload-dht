

# *Stage 2. Асинхронный сервер*

## *Нагрузочное тестирование с помощью wrk* 

Для того, чтобы понять являются ли внесенные изменения эффективными, было проведено нагрузочное тестирование `GET`  и`PUT`запросами до модификации и после. Для обоих типов запросов был выбран `RATE` равный `15000`, при котором сервер стабильно имел среднее время ответа выше `1ms`, что нас неустраивает.  

<hr>

### *PUT*

Результаты до модификации обработки запросов имеет неприемлемое значение `Latency ` равное `3.87ms`

```
1 threads and 1 connections
  Thread calibration: mean lat.: 3.670ms, rate sampling interval: 22ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     3.78ms    5.64ms  44.00ms   86.36%
    Req/Sec    15.35k     3.75k   36.14k    77.07%
  449976 requests in 30.00s, 28.75MB read
Requests/sec:  14999.11
Transfer/sec:      0.96MB
```

Сервер однозначно не справляется с нагрузкой. 

После внесения модификаций:

```
1 threads and 1 connections
  Thread calibration: mean lat.: 24.973ms, rate sampling interval: 197ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   739.15us    0.87ms  21.58ms   97.62%
    Req/Sec    15.04k    98.77    15.67k    97.03%
  449987 requests in 30.00s, 28.75MB read
Requests/sec:  14999.24
Transfer/sec:      0.96MB
```

Среднее время ответа стало лучшее более, чем в `5` раз, из чего можно сделать вывод, что добавление асинхронности серверу имеет очень большое значение.

<hr>

## *GET*

До модификации сервер так же не справлялся с `GET` запросами (при условии, что бьют по разным ключам, если по одному, то значение кешируется и выдает допустимый перфоманс):

```
1 threads and 1 connections
  Thread calibration: mean lat.: 26.249ms, rate sampling interval: 90ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     4.10ms    5.98ms  41.57ms   86.38%
    Req/Sec    15.08k     1.69k   20.84k    76.58%
  449976 requests in 30.00s, 29.50MB read
Requests/sec:  14999.49
Transfer/sec:      0.98MB
```

После добавления асинхронности сервер в среднем стал в `6` раз быстрее отвечать на запросы и попадать в `avg(latency) < 1ms`:

```
1 threads and 1 connections
  Thread calibration: mean lat.: 18.532ms, rate sampling interval: 106ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   658.67us  375.47us   6.29ms   61.69%
    Req/Sec    15.08k   108.67    15.65k    75.00%
  449986 requests in 30.01s, 29.50MB read
Requests/sec:  14996.31
Transfer/sec:      0.98MB
```


<hr>

Данные результаты были получены при использовании одного потока и одного подключения, если же увеличить количество потоков и соединений, например, до значений `-t 4 -c 64`, то перфоманс будет идентичный, что до внедрения асинхронности, что после.

## *Профилирование с помощью async-profiler*

При профилировании было выявлено, что плюсы, которые привносит асинхронность, а именно параллельная обработка запросов и разгрузка селекторов, нивелируется блокировками очереди. Примерно `10% CPU` тратится на обработку метода `take()` у реализации блокирующей очереди. За счет асинхронности аллокации стали распределены равномерно, но блокирующая очередь так же требует дополнительных аллокаций. В целом, добавление ассинхронности дает заметное улучшение перфоманса при низкой нагрузке на сервер, но, если нагрузка возрастает, то возрастает и дополнительные расходы, алгоритм явно нуждается в доработке.