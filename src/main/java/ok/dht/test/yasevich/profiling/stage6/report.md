* в директории тестовой ноды находятся записи вида key = n, value = n, для n от 000000 до 999999
* напишем [скрипт](../scripts/get-range.lua) для тестирования

Скрипт берёт случайное число от 0 до 999999 в качестве параметра start и прибавляет ширину диапазона, чтобы получить
параметр end. Оба значения нужно дополнить нулями (или нулевыми байтами), чтобы сохранить лексикографический порядок
ключей. Также учитывается случай, если end получается больше 999999, т.к. в таком случае он может быть лексикографически
меньше, чем start.

Попробуем разные значения шиирны диапазона. Начнём с 100

## Первая реализация

### Диапазон 100

Для диапазона 100 имеем:

* rate 7000 - результаты [не очень](wrk/v1/range100-rate7000)
    * средняя задержка `35.06ms`
    * имеем задержку `100ms` начиная с перцентиля `90%`
    * `200ms` начиная с `95.6%`
    * `693.76ms` для `100%`
* rate 6500 - [норм](wrk/v1/range100-rate6500)
    * средняя `11.53ms`
    * задержка `100ms` начиная с перцентиля `99%`
    * `251.13ms` для `100%`

Запустим профилирование для диапазона `100` и rate `6500`.

Результаты [cpu](html/cpu1.html):

* Видим, что для селекторов из `63,65%` сэмплов около `14%` - это работа с dao
* В воркерах всего `4.78%` сэмплов :)
    * из которых `2.73%` - это take() из очереди
    * `1.99%` - sendResponse()

### Диапазон 1000

Для диапазона 1000 имеем:

* rate 800 - [плохо](wrk/v1/range1000-rate800)
* rate 600 - [лучше](wrk/v1/range1000-rate600), однако
    * задержка `100ms` с перцентиля `90%` и `200ms` с `94%`
    * `991.74ms`! - `100%`

### Диапазон 10000

Для диапазона 10000 - не справляемся даже c rate 50.
Наверное для такого диапазона не имеет смысл измерять задержку получения полного ответа.

## Вторая реализация

Исправим реализацию и вынесем работу с dao из селекторов.
Также, в том числе нужно сделать [получение итератора](img/iterator.png) и [аллокацию буфера](img/buffer.png)
лениво, при первом writeAsync()

### Диапазон 100

Для диапазона 100 имеем:

* rate 15000 - результаты [не очень](wrk/v2/range100-rate15000)
    * средняя задержка `9.75ms`
    * для перцентиля `90%` задержка `28.53ms`
    * за `100ms` переваливаем начиная с `98%`
    * за `200ms` переваливаем с `99.8%`
    * `298.50ms` для `100%`
* rate 10000 - [норм](wrk/v2/range100-rate10000)
    * средняя задержка `5.37ms`
    * для перцентиля `90%` задержка `10.74ms`
    * за `100ms` переваливаем начиная с `99.8%`
    * `179.71ms` для `100%`

В сравнении с первой реализацией получили примерно те же цифры, но для в два раза большего rate.

Запустим профилирование для диапазона `100` и rate `10000`.

Результаты [cpu](html/cpu2.html):

* `11.92%` + `5.93%` сэмплов для селекторов
    * работа с dao отсутствует
    * остались только работа с сессией, парсинг запросов и queue.offer()
* Для воркеров:
    * ~`20%` init() метод в методе getChunks()
        * `13%` сэмплов - аллокации буфера
        * `6.92%` взятие итератора
    * ~`30%` getChunks()
    * `16%` парков
    * `9.33%` работа сборщика мусора

Результаты [alloc](html/alloc2.html):

* `10%` аллокаций MappedMemorySegmentImpl на получение итератора
* `0.25%` аллокаций на direct ByteBuffer
* `25%` аллокаций MappedMemorySegmentImpl на метод Iterator.hasNext()
* `31%` аллокаций byte[] на метод Iterator.peek()
* `11%` аллокаций byte[] для Integer.toHexString и String.getBytes в методе putEntry() в ChunkedResponse

Последний пункт стоило бы попробовать оптимизировать

### Диапазон 1000

Для диапазона 1000 - рабочий rate теперь [2000](wrk/v2/range1000-rate2000):

* средняя задержка `7.06ms`
* для перцентиля `90%` задержка `17.55ms`
* за `100ms` переваливаем начиная с `99.9%`
* `122.81ms` для `100%`

## Итого

* Исправили реализацию, вынесли работу с dao из селекторов и получили прирост рабочего rate
* Для запросов на получение диапазона из 100 записей получили rate того же порядка, что и rate для обычных запросов

