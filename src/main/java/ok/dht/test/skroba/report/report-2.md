# Stage 2

Scripts:

1. WRK with put.
```
wrk2 -t 64 -c 64 -d 60s -R 30000 http://localhost:3000 -s put.lua
wrk2 -t 64 -c 64 -d 60s -R 600000 http://localhost:3000 -s put.lua
```

Results:

```
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     0.95ms    2.05ms  69.89ms   99.40%
    Req/Sec   492.36     57.04     1.90k    65.22%
  1799795 requests in 1.00m, 115.00MB read
Requests/sec:  30003.11
Transfer/sec:      1.92MB

  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    29.38s    12.01s   50.79s    58.50%
    Req/Sec     1.48k    26.89     1.53k    69.27%
  5683766 requests in 1.00m, 363.17MB read
Requests/sec:  94750.91
Transfer/sec:      6.05MB

```

2. WRK with get.

```
wrk2 -t 64 -c 64 -d 60s -R 30000 http://localhost:3000 -s get.lua
wrk2 -t 64 -c 64 -d 60s -R 600000 http://localhost:3000 -s get.lua
```


```
    Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     1.14ms    3.07ms  90.24ms   98.81%
    Req/Sec   492.11     63.55     1.89k    86.19%
  1799862 requests in 1.00m, 121.87MB read
Requests/sec:  30002.92
Transfer/sec:      2.03MB

  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    28.59s    11.65s   50.95s    58.51%
    Req/Sec     1.50k    22.71     1.54k    63.54%
  5576065 requests in 1.00m, 377.56MB read
Requests/sec:  92952.12
Transfer/sec:      6.29MB

```

Были проведены несколько испытаний, чтобы посмотреть производительность реализации.
В данной реализации использовалось `LinkedBlockingQueue` для организации очереди в формате FIFO.

Как показывают запуски wrk количество запросов, которое может стабильно обрабатывать наш сервер возросло, причем значительно.
Для того чтобы сервер начал захлебываться нужно порядка 1000000 запросов.

Был проведен также подбор параметров, таких как количество потоков в пуле. Максимальное количество элементов в очереди и метод приоритета для очереди.

К сожалению, метод приоритета подобрать не получилось, тк при различных запусках результаты были разными и понять верный не получилось.
Оптимальным же количеством мест в очереди оказалось от 500 до 1500, при меньших мы получаем много 500 ответов, большом мы теряем в производительности. 

## Вывод:

Исходя из графиков наша производительность выросла, но при этом у нас появились дополнительные проблемы.

Pros:

* Теперь большую часть работы занимает работа с сетью(те ее мы не усовершенствуем, ибо она ~идеальна),
* Теперь наши мощности меньше простаивают особенно это видно по цвету графиков.
* Количество запросов для стабильной работы сервера сильно возросло.

Но плюсы не так интересны как минусы.

Cons: 

* У нас начало тратиться много времени на синхронизацию и блокировки для очереди содержащей нашу обработку запросов.
* Все еще есть время, когда процесс ожидает результата. При get запросе мы долго ожидаем ответа от бд(мы с этим ничего не можем сделать, бд это отдельная система мы ее не меняем).

По моему виденью, есть несколько моментов которые можно улучшить:
1. Попробовать использовать структуру данных без блокировок, таких как `LockFreeStack`. Не факт, что мы не получим проблем в других местах, но это должно помочь отыграть хоть часть времени тратящуюся на блокировки.
2. Работать асинхронно, чтобы наш поток не простаивал пока мы ожидаем результата от бд. 

Замечание:
При наших нагрузках на вычисления при обработке ответа, сложно что-то сильно оценивать, тк результат был бы более нагляден при увелечении времени обработки вычислений, тк в данный момент наши оптимизации сильно подпорчиваются сопутствующими нагрузками от оптимизаций. (Синхронизация та же)  
