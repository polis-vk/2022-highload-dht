# Отчет по второму этапу HIGHLOAD

Так как база данных была изменена на RocksDB, то надо повторить процедуру с
предыдущего этапа для нахождения стабильной нагрузки на путе (бинарным поиском получаем 21k - RTS)
(запуск на реализации из первого этапа)


## PUT

Запустим на старой версии:

``` 
wrk -d 60 -t 1 -c 1 -R 21000 http://localhost:19234 -s ../2022-highload-dht/src/main/java/ok/dht/test/vihnin/resources/report/stage1/put.lua
Running 1m test @ http://localhost:19234
  1 threads and 1 connections
  Thread calibration: mean lat.: 0.712ms, rate sampling interval: 10ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    43.63ms   84.93ms 361.47ms   87.50%
    Req/Sec    22.20k     2.87k   35.00k    73.24%
  1259987 requests in 1.00m, 80.51MB read
Requests/sec:  20999.59
Transfer/sec:      1.34MB
```


[cpu](./htmls/t1_c1_R21000_put_cpu.html)
[alloc](./htmls/t1_c1_R21000_put_alloc.html)
[lock](./htmls/t1_c1_R21000_put_lock.html)


А теперь на параллельной версии:

``` 
wrk -d 60 -t 4 -c 64 -R 20000 http://localhost:19234 -s ../2022-highload-dht/src/main/java/ok/dht/test/vihnin/resources/report/stage2/put.lua
Running 1m test @ http://localhost:19234
  4 threads and 64 connections
  Thread calibration: mean lat.: 1.345ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.291ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.330ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 1.411ms, rate sampling interval: 10ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     1.04ms  725.61us  25.06ms   88.53%
    Req/Sec     5.26k   406.13    11.11k    85.77%
  1199244 requests in 1.00m, 76.63MB read
Requests/sec:  19987.21
Transfer/sec:      1.28MB
```


[cpu](./htmls/t4_c64_R20000_put_cpu.html)
[alloc](./htmls/t4_c64_R20000_put_alloc.html)
[lock](./htmls/t4_c64_R20000_put_lock.html)


Давайте сравним показатель на сpu:
1. Можем заметить, что с 85% до %15 от общей работы упало участие SelectorThread-a, что и привело к повышению
максимального RTS
2. Также заметим, что процент занимаемый работой RocksDB примерно одинаковый (~47%), что нельзя
по-видимому улучшить, так как оно зависит от реализации бд, но конечно не исключено. В любом случае
это нынешними нововведениями не исправить.

В alloc:
1. В случае многопоточной реализации мы получаем, что процент parsing-a Selector начинаем занимать
основную часть, так как вычисления приходятся не него




``` 
wrk -d 60 -t 4 -c 64 -R 50000 http://localhost:19234 -s ../2022-highload-dht/src/main/java/ok/dht/test/vihnin/resources/report/stage2/put.lua
Running 1m test @ http://localhost:19234
  4 threads and 64 connections
  Thread calibration: mean lat.: 153.197ms, rate sampling interval: 832ms
  Thread calibration: mean lat.: 159.530ms, rate sampling interval: 849ms
  Thread calibration: mean lat.: 158.337ms, rate sampling interval: 844ms
  Thread calibration: mean lat.: 162.383ms, rate sampling interval: 868ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   560.38ms  648.61ms   3.52s    91.11%
    Req/Sec    11.70k     1.65k   13.85k    82.83%
  2826226 requests in 1.00m, 180.59MB read
Requests/sec:  47103.74
Transfer/sec:      3.01MB

```


[cpu](./htmls/t4_c64_R50000_put_cpu.html)
[alloc](./htmls/t4_c64_R50000_put_alloc.html)
[lock](./htmls/t4_c64_R50000_put_lock.html)

``` 
wrk -d 60 -t 4 -c 64 -R 70000 http://localhost:19234 -s ../2022-highload-dht/src/main/java/ok/dht/test/vihnin/resources/report/stage2/put.lua
Running 1m test @ http://localhost:19234
  4 threads and 64 connections
  Thread calibration: mean lat.: 747.211ms, rate sampling interval: 2902ms
  Thread calibration: mean lat.: 741.353ms, rate sampling interval: 2869ms
  Thread calibration: mean lat.: 877.433ms, rate sampling interval: 3035ms
  Thread calibration: mean lat.: 881.727ms, rate sampling interval: 3039ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     7.63s     3.70s   15.20s    57.99%
    Req/Sec    12.84k     1.06k   14.68k    65.15%
  3106290 requests in 1.00m, 198.48MB read
Requests/sec:  51771.77
Transfer/sec:      3.31MB
```


[cpu](./htmls/t4_c64_R70000_put_cpu.html)
[alloc](./htmls/t4_c64_R70000_put_alloc.html)
[lock](./htmls/t4_c64_R70000_put_lock.html)

Выводы: выдерживает большие нагрузки

## GET

Будет пробовать запустить с RTS=20000 get на заполненной базе, но менять на ней размер очереди,
то есть `QUEUE_CAPACITY`

### Значения на разных очередях

QUEUE_CAPACITY = 100

``` 
Running 1m test @ http://localhost:19234
  4 threads and 64 connections
  Thread calibration: mean lat.: 0.955ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 0.949ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 0.964ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 0.950ms, rate sampling interval: 10ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     1.07ms    1.48ms  61.02ms   98.67%
    Req/Sec     5.27k   471.91    17.00k    91.69%
  1199259 requests in 1.00m, 5.66GB read
Requests/sec:  19987.72
Transfer/sec:     96.55MB
```


[cpu](./htmls/t4_c64_R20000_get_cpu.html)
[alloc](./htmls/t4_c64_R20000_get_alloc.html)
[lock](./htmls/t4_c64_R20000_get_lock.html)


QUEUE_CAPACITY = 30

``` 
Running 1m test @ http://localhost:19234
  4 threads and 64 connections
  Thread calibration: mean lat.: 0.971ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 0.976ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 0.970ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 0.968ms, rate sampling interval: 10ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     1.05ms    1.13ms  45.28ms   98.22%
    Req/Sec     5.26k   461.84    18.11k    91.81%
  1199337 requests in 1.00m, 5.64GB read
  Non-2xx or 3xx responses: 2792
Requests/sec:  19988.66
Transfer/sec:     96.33MB
```

[cpu](./htmls/t4_c64_R20001_get_cpu.html)
[alloc](./htmls/t4_c64_R20001_get_alloc.html)
[lock](./htmls/t4_c64_R20001_get_lock.html)

Вывод: Очевидно, что при уменьшении очереди начинаются появляться дропы (пример два).

## Выводы

В общем можно наблюдать повышение производительности нашего сервера, так как распараллелилась
обращение к бд, которая и занимает основную часть времени, так что мы точно разгрузили SelectorThread.
Но столкнули с тем, что стали зависимы от размера очереди, так что теперь надо грамотно подбирать еще и этот параметр, 
иначе можем и ухудшить ситуацию.