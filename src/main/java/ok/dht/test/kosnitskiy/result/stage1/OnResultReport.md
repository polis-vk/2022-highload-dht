Была создана база, занимающая 6.4Gb места, имеющая 768 файлов по 8.4мб каждый. Размер каждой записи составил 200кб

Рассмотрим GET запросы
Заметим, что когда мы рассматриваем лучшие случаи - получаем результат одного и того же ключа, база показывает результаты
в десятки раз лучше, чем когда ключа нет или ключи разные. 
Оно и понятно, когда ключ запрашивается один и тот же, происходит кеширование этой записи в InMemory части базы данных, 
что позволяет в конечном счете его очень быстро и четко получать снова и снова, если это потребуется

С другой стороны, когда ключа в базе нет, чтобы доказать этот факт базе приходится пройтись по всем файлам, начиная
с самого нового и заканчивая самым старым. Это занимает много времени от того и видим критическое падение производительности.
Для решения этой проблемы нам стоило бы реализовать фильтр Блума:
Если элемент существет в базе, то фильтр Блума никогда не обманет и скажет о его существовании
Если элемент не существует в базе, то фильтр Блума с высокой вероятностью скажет, что его там нет (но иногда может соврать)
Дополнение базы фильтром блума позволит существенно сократить время выполнения запросов с несущ. ключами

Если же ключи разные, то ситуация становится еще хуже - нам приходится искать по всей базе начиная с самого свежего файла,
заканчивая самым старым (прямо как с несуществующим ключом), однако теперь нам еще надо будет подгружать найденное значение
и отправлять его клиенту. Это поджирает еще немного производительности.

Теперь поговорим про PUT запросы
Заметим, что лучший случай и худший случай работают очень быстро, на уровне лучшего случая GET запроса по скорости
и не особо отличаются даже друг от друга по производительности. Это связано с тем, что худший случай лишь заставляет нас
асинхронно переходить к записи новых файлов на диск, отсюда и небольшая потеря в производительности, когда как в лучшем
случае происходит перезапись одного и того же ключа в InMemory хранилище.

Это все позволяет нам сделать вывод, что LSM дерево действительно очень хорошо подходит для быстрой записи новых данных,
даже если мы записываем абсолютно разные ключи и значения, однако очень плохо подходит для быстрого чтения данных,
особенно учитывая, что в реальной жизни ключи скорее всего будут всегда разные, а так же будет много запросов на несуществующие ключи.

Рассмотрим нагрузку, которую способна выдержать база в данный момент с цифрами:

GET:
Если говорить про самый популярный кейс - разные существующие ключи, то наша производительность останавливается примерно на уровне
500 GET запросов в секунду. Повышение планки до 600 еще отрабатывает +- адекватно, однако MAX время очень сильно подскакивает
По результатам стресс теста, можно заметить, что мы способны обрабатывать в среднем 700-800 GET запросов несуществующих ключей 
в секунду. Продолжая увеличивать нагрузку мы начинаем получать непозволительную задержку на ответ. Особенно сильно пугает MAX время ответа,
которое при переходе с 800 на 900 запросов увеличилось в 4 раза - с 9 до 37 ms!
С другой стороны если мы рассматриваем лучший случай GET с получением одного и того же ключа, то мы можем рассчитывать
на обработку 17000-18000 запросов в секунду. Что лучше обычного плохого случая более чем в 20 раз! В некоторых узких
кейсах эта информация может оказаться довольно важной

При анализе PUT замечаем, что даже при "худшем" случае мы легко сможем выдержать 15000 запросов в секунду. При рассмотрении
наилучшего случая максимальная адекватная нагрузка возрастает до 17000-18000 запросов в секунду.

Анализ графиков:

PUT
Заметим, что при выполнении PUT запросов большую часть времени занимает выполнение one.nio Это, вероятно,
может служить свидетельством того, что код нашей бд сам по себе отрабатывает довольно достойно по скорости, что в принципе
ожидаемо, так как в нашей базе данных реализован неблокирующий flush, а потому все, что требуется от кода нашей бд - это
положить значение в InMemory хеш мапу.
Зато анализируя аллокацию памяти, можно заметить, что довольно существенное время в ней уделяется на выделение памяти
под String - который мы используем в методе put только для аргумента - id, который в дальнейшем все равно преобразуем в
массив байтов. one.nio.util.Utf8.toAsciiString и one.nio.util.Utf8.read тоже тратят время и вероятно связаны с этой id,
которую мы принимаем строкой. Было бы классно принимать ее как массив байтов, прямо как мы делаем с body, например. Уверен
что это смогло бы дать нам относительно неплохой прирост

Так же стоит заметить(относится и к PUT и к GET), что из-за перекомпилирования кода джитом время от времени возникают моменты, когда
мы запросы не обрабатываем вообще, а занимаемся только перекомпиляцией кода, т.е наш сервер стоит, возможно это 
может очень пагубно влиять на максимальное время запросов. Было бы славно, если бы мы смогли сделать так, чтобы 
джит компилировал наш код в отдельном треде, делал бы новый готовый к работе инстанс сервера, а потом бы бесшовно
переходил со старого на новый, возможно это бы было бы эффективнее и не было бы такого страшного простоя время от времени,
однако это, конечно, больше из разряда фантастики наверное, однако скорее всего это будет иметь смысл, так как мы можем
заметить, что джит любит проводить оптимизации динамически, в зависимости от загрузки нашего сервера и того, какие именно
запросы мы посылаем. Так как в реальном использовании загрузка сервера будет постоянно разная и под разные запросы, то
вероятно джит будет перекомпилировать части нашего сервера на постоянной основе, а потому думать над оптимизацией поведения
джита точно будет иметь смысл

GET
При обработке Get запросов CPU нагружен намного сильнее, это связано с тем, что GET - куда более сложная операция для нас,
естественно тут наша DAO работает уже больше чем one.nio, особенно много обращений к памяти происходит, оно и понятно, ведь
данные мы читаем с диска. С учетом того, что данные у нас хранятся на NVME, многопоточность здесь нам явно очень поможет
ведь SSD хорошо работают с многопоточными обращениями к ним. С другой стороны можно отметить, что в отличие от PUT запросов,
где процессор загружен не особо сильно, здесь график загрузки процессора почти весь красный, так что просижевающего ресурса
процессора, который мы сможем утилизировать при многопотоке, остается гораздо меньше, чем в PUT запросах. Для put запросов
нам, вероятно, хорошо бы подошел очень многоядерный процессор с довольно слабыми ядрами, в каком-то плане сразу на ум
приходит видеокарта, а тут, в GET запросах, нам все же нужны будут нормальные, высокопроизводительные ядра, чтобы работать
с этой прелестью в многопотоке. Выделяем памяти мы при GET запросах куда больше, чем при PUT запросах. Из этого так же можно
сделать вывод, что производительность GET запросов будет куда сильнее зависеть от скорости и количества нашей оперативной памяти 
и производительности SSD накопителя, чем при PUT запросах. Так же при PUT запросах много времени уходит на проверки, такие как
jdk.internal.foreign.AbstractMemorySegmentImpl.isSet jdk.internal.foreign.AbstractMemorySegmentImpl.isSmall
jdk.internal.foreign.AbstractMemorySegmentImpl.checkBounds jdk.internal.foreign.AbstractMemorySegmentImpl.checkAccess
Возможно можно ускорить код уменьшив количество таких проверок до минимума, работая более дерзко, так как мне кажется,
что зачастую такие проверки могут остаться из-за желания заставить код заработать, не допустить вылетов и эксепшенов, но
еще раз пройдясь по ним получится уменьшить количество действительно необходимых проверок в несколько раз.
